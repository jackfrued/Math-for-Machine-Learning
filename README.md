## 机器学习数学基础知识

很多人学习机器学习都是从模型和框架入手的，我们学会了如何调用三方库、如何处理数据集、如何训练模型、如何参数调优，如何部署模型。但是很多人可能跟我一样，在学习的过程中总会遇到一些熟悉又陌生的词，例如：特征值、Hessian、最大似然、KL 散度、正则化、凸性等等。你知道它们重要，却不确定它们究竟在做什么，不确定它们对你从事机器学习的工作有多大的意义。创建这个仓库的初衷其实很简单，给正在学习机器学习的人，准备一份可以随时回看的数学地图。它不是传统意义上的数学教材，作者的水平也写不出什么数学教材（因为我自己的数学其实也不怎么样）。所以，在这些文档中，你可能看不到复杂的计算技巧，也不会被大量抽象的定理淹没；相反，我们只关心一件事，这些数学结构在机器学习中究竟扮演什么角色。当你学习线性回归时，这里会解释“投影”到底意味着什么；当你接触 PCA 时，你会真正理解特征值为什么在寻找数据的主方向；当你看到梯度下降时，你会明白梯度不仅仅是一个公式，而是“局部最陡上升方向”的几何表达；当你用交叉熵训练分类器时，你会知道它与信息熵、KL 散度之间的内在联系；当模型过拟合时，你也能从偏差–方差、泛化误差的角度去理解，而不是只停留在经验层面。

这套内容大致覆盖几个核心板块：线性代数与矩阵分解、多变量微积分与优化、概率与统计建模、信息论与损失函数、以及与泛化能力相关的学习理论。每一部分都围绕“算法背后的数学结构”展开，而不是孤立地讲公式。在今天，调用模型越来越容易，但真正理解模型却越来越稀缺。理解数学并不是为了炫技，而是为了建立判断力量。当训练不收敛时，你知道该怀疑梯度还是数据；当模型效果不稳定时，你能思考是偏差问题还是方差问题；当看到新的算法时，你可以迅速抓住它的数学核心，而不是被表面的结构迷惑。你可以把它当作机器学习之前的预备阅读，也可以在学习过程中随时翻阅。它更像一张底层结构图，而不是一条必须按顺序走完的路线。如果它能帮助你在某个关键时刻“想明白一件事”，那这份分享就已经有意义了。

1. [向量空间与矩阵计算](./01.向量空间与矩阵计算.md)
    - 向量与矩阵
    - 矩阵分解
    - 线性变换
    - 矩阵乘法的意义
    - 投影矩阵
    - 正交矩阵
    - 最小二乘的几何解释
    - 特征值和特征向量
    - 协方差矩阵
    - 二次型
    - Hessian
    - 正定矩阵与凸函数
    - 奇异值分解
    - Frobenius 范数
2. [多变量微积分](./02.多变量微积分.md)
    - 函数和极限
    - 导数和偏导数
    - 泰勒公式
    - 牛顿法
    - 收敛速度
    - Adam的数学结构
3. [概率论](./03.概率论.md)
    - 随机和概率
    - 随机变量及其分布
    - 条件概率
    - 贝叶斯公式
4. [统计学习基础](./04.统计学习基础.md)
    - 最大似然估计
    - 线性回归
    - 逻辑回归
    - MAP
    - 正则化
5. [优化理论](./05.优化理论.md)
    - 凸函数和凸优化
    - Jensen 不等式
    - 拉格朗日乘子
    - 梯度下降法
    - 正则化方法
    - 约束优化
6. [信息论与损失函数](./06.信息论与损失函数.md)
    - 信息熵
    - 条件熵和信息增益
    - KL散度
    - 互信息
    - Softmax
    - 最大熵模型
    - Transformer 中的 KL
7. [泛化与学习理论](./07.泛化与学习理论.md)
    - 经验风险最小化
    - 过拟合
    - 正则化
    - 泛化误差
8. [补充内容](./08.补充内容.md)

